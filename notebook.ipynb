{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6087cd68-dab9-43a9-a0d8-864ae2168e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Logging\n",
    "#\n",
    "\n",
    "#import logging\n",
    "#import sys\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import os.path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304c079-3d06-4b68-bb26-a7cd0f1e0c85",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114bd6b2-be89-41a3-8aac-a7c49746c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a66a9-ac0c-4a31-856e-07993c050df3",
   "metadata": {},
   "source": [
    "## Querying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae695bf-1481-471b-af25-4447cab60ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enginer to query the index\n",
    "\n",
    "# https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/\n",
    "# \"If you want to have a conversation with your data (multiple back-and-forth instead of a single question & answer), \n",
    "# take a look at Chat Engine\"\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a47a61-3abc-4154-998a-2cc3e3895dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author focused on writing short stories and programming, starting with early attempts on an IBM 1401 using Fortran in 9th grade. Later, with the introduction of microcomputers like the TRS-80, the author delved deeper into programming, creating simple games, a rocket height prediction program, and a word processor.\n"
     ]
    }
   ],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/understanding/querying/querying/\n",
    "# \" querying is just a prompt call to an LLM\"\n",
    "# Querying consists of three distinct stages:\n",
    "# 1. Retrieval is when you find and return the most relevant documents for your query from your Index. As previously discussed in indexing, the most common type of retrieval is \"top-k\" semantic retrieval, but there are many other retrieval strategies.\n",
    "# 2. Postprocessing is when the Nodes retrieved are optionally reranked, transformed, or filtered, for instance by requiring that they have specific metadata such as keywords attached.\n",
    "# 3. Response synthesis is when your query, your most-relevant data and your prompt are combined and sent to your LLM to return a response.\n",
    "\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
